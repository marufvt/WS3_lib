{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecb42eb-e411-44c9-ad44-eb84cf022ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maruf/newenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "step:    0/  455 loss_cls:0.7128 loss_sal:0.0001 imps:5.1 lr: 0.1000 etc:Fri Nov 11 21:13:58 2022\n",
      "step:   20/  455 loss_cls:0.2665 loss_sal:0.0005 imps:11.3 lr: 0.0960 etc:Fri Nov 11 21:00:53 2022\n",
      "step:   40/  455 loss_cls:0.2399 loss_sal:0.0007 imps:11.5 lr: 0.0921 etc:Fri Nov 11 21:00:36 2022\n",
      "step:   60/  455 loss_cls:0.2326 loss_sal:0.0014 imps:11.4 lr: 0.0880 etc:Fri Nov 11 21:00:42 2022\n",
      "step:   80/  455 loss_cls:0.2152 loss_sal:0.0031 imps:11.2 lr: 0.0840 etc:Fri Nov 11 21:00:53 2022\n",
      "validating ... loss: 0.1939\n",
      "Epoch 2/5\n",
      "step:  100/  455 loss_cls:0.2065 loss_sal:0.0051 imps:10.0 lr: 0.0800 etc:Fri Nov 11 21:02:03 2022\n",
      "step:  120/  455 loss_cls:0.1876 loss_sal:0.0087 imps:10.3 lr: 0.0759 etc:Fri Nov 11 21:01:59 2022\n",
      "step:  140/  455 loss_cls:0.1601 loss_sal:0.0128 imps:10.4 lr: 0.0718 etc:Fri Nov 11 21:01:56 2022\n",
      "step:  160/  455 loss_cls:0.1641 loss_sal:0.0183 imps:10.4 lr: 0.0677 etc:Fri Nov 11 21:01:54 2022\n",
      "step:  180/  455 loss_cls:0.1521 loss_sal:0.0165 imps:10.4 lr: 0.0636 etc:Fri Nov 11 21:01:53 2022\n",
      "validating ... loss: 0.1165\n",
      "Epoch 3/5\n",
      "step:  200/  455 loss_cls:0.1353 loss_sal:0.0176 imps:10.2 lr: 0.0594 etc:Fri Nov 11 21:02:23 2022\n",
      "step:  220/  455 loss_cls:0.1298 loss_sal:0.0216 imps:10.3 lr: 0.0552 etc:Fri Nov 11 21:02:20 2022\n",
      "step:  240/  455 loss_cls:0.1369 loss_sal:0.0196 imps:10.4 lr: 0.0509 etc:Fri Nov 11 21:02:16 2022\n",
      "step:  260/  455 loss_cls:0.1332 loss_sal:0.0194 imps:10.4 lr: 0.0466 etc:Fri Nov 11 21:02:14 2022\n",
      "validating ... loss: 0.1223\n",
      "Epoch 4/5\n",
      "step:  280/  455 loss_cls:0.1172 loss_sal:0.0213 imps:9.9 lr: 0.0423 etc:Fri Nov 11 21:02:34 2022\n",
      "step:  300/  455 loss_cls:0.1102 loss_sal:0.0220 imps:10.3 lr: 0.0379 etc:Fri Nov 11 21:02:31 2022\n",
      "step:  320/  455 loss_cls:0.1031 loss_sal:0.0224 imps:10.4 lr: 0.0335 etc:Fri Nov 11 21:02:28 2022\n",
      "step:  340/  455 loss_cls:0.1172 loss_sal:0.0204 imps:10.4 lr: 0.0290 etc:Fri Nov 11 21:02:25 2022\n",
      "step:  360/  455 loss_cls:0.1073 loss_sal:0.0223 imps:10.4 lr: 0.0244 etc:Fri Nov 11 21:02:23 2022\n",
      "validating ... loss: 0.0956\n",
      "Epoch 5/5\n",
      "step:  380/  455 loss_cls:0.0997 loss_sal:0.0246 imps:10.1 lr: 0.0197 etc:Fri Nov 11 21:02:37 2022\n",
      "step:  400/  455 loss_cls:0.0900 loss_sal:0.0247 imps:10.3 lr: 0.0149 etc:Fri Nov 11 21:02:35 2022\n",
      "step:  420/  455 loss_cls:0.0929 loss_sal:0.0234 imps:10.3 lr: 0.0099 etc:Fri Nov 11 21:02:33 2022\n",
      "step:  440/  455 loss_cls:0.0834 loss_sal:0.0261 imps:10.3 lr: 0.0046 etc:Fri Nov 11 21:02:31 2022\n",
      "validating ... loss: 0.0971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "cudnn.enabled = True\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import importlib\n",
    "\n",
    "import voc12.dataloader\n",
    "from misc import pyutils, torchutils\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def validate(model, data_loader):\n",
    "    print('validating ... ', flush=True, end='')\n",
    "\n",
    "    val_loss_meter = pyutils.AverageMeter('loss1', 'loss2')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pack in data_loader:\n",
    "            img = pack['img'].to(device)\n",
    "            label = pack['label'].to(device)\n",
    "\n",
    "            x = model(img)\n",
    "            loss1 = F.multilabel_soft_margin_loss(x, label)\n",
    "\n",
    "            val_loss_meter.add({'loss1': loss1.item()})\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    print('loss: %.4f' % (val_loss_meter.pop('loss1')))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = getattr(importlib.import_module('net.resnet50_cam'), 'Net')()\n",
    "\n",
    "\n",
    "train_dataset = voc12.dataloader.VOC12ClassificationDataset('/home/maruf/ws2m2/voc12/train.txt', voc12_root='/home/amartyadutta/VOC12/AMN/Datasets/VOCdevkit/VOC2012',\n",
    "                                                            resize_long=(320, 640), hor_flip=True,\n",
    "                                                            crop_size=512, crop_method=\"random\")\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16,\n",
    "                               shuffle=True, num_workers=8, pin_memory=True, drop_last=True)\n",
    "max_step = (len(train_dataset) // 16) * 5\n",
    "\n",
    "val_dataset = voc12.dataloader.VOC12ClassificationDataset('/home/maruf/ws2m2/voc12/val.txt', voc12_root='/home/amartyadutta/VOC12/AMN/Datasets/VOCdevkit/VOC2012',\n",
    "                                                          crop_size=512)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=16,\n",
    "                             shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "param_groups = model.trainable_parameters()\n",
    "optimizer = torchutils.PolyOptimizer([\n",
    "    {'params': param_groups[0], 'lr': 0.1, 'weight_decay': 0.0001},\n",
    "    {'params': param_groups[1], 'lr': 10*0.1, 'weight_decay': 0.0001},\n",
    "], lr=0.1, weight_decay=0.0001, max_step=max_step)\n",
    "\n",
    "# model = torch.nn.DataParallel(model).to(device)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "avg_meter = pyutils.AverageMeter()\n",
    "\n",
    "timer = pyutils.Timer()\n",
    "\n",
    "for ep in range(5):\n",
    "    \n",
    "    print('Epoch %d/%d' % (ep+1, 5))\n",
    "    \n",
    "    for step, pack in enumerate(train_data_loader):\n",
    "\n",
    "        img = pack['img'].to(device)\n",
    "        label = pack['label'].to(device)\n",
    "\n",
    "        img.requires_grad = True\n",
    "        \n",
    "        # additional for robustness\n",
    "        noise_probability = torch.ones_like(img)*0.75\n",
    "        noise = torch.bernoulli(noise_probability).detach()\n",
    "        noise.requires_grad = True\n",
    "        \n",
    "        out = model(img*noise)\n",
    "        scores = (out*label).sum(-1)\n",
    "        \n",
    "        saliency = torch.autograd.grad(\n",
    "                scores, noise,\n",
    "                grad_outputs = torch.ones(len(scores), device=device),\n",
    "                retain_graph=True,\n",
    "                create_graph=True\n",
    "            )[0]\n",
    "\n",
    "        grad_x, grad_y = torch.gradient(saliency, dim=(-1, -2))\n",
    "        loss_reg = torch.linalg.norm(grad_x ** 2 + grad_y ** 2)\n",
    "        # loss_reg = torch.linalg.norm(saliency)\n",
    "        \n",
    "        loss_cls = F.multilabel_soft_margin_loss(out, label)\n",
    "        \n",
    "        loss = 1 * loss_cls + 1 * loss_reg\n",
    "\n",
    "        avg_meter.add({'loss_cls': loss_cls.item()})\n",
    "        avg_meter.add({'loss_sal': loss_reg.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (optimizer.global_step-1)%20 == 0:\n",
    "            timer.update_progress(optimizer.global_step / max_step)\n",
    "\n",
    "            print('step:%5d/%5d' % (optimizer.global_step - 1, max_step),\n",
    "                  'loss_cls:%.4f' % (avg_meter.pop('loss_cls')),\n",
    "                  'loss_sal:%.4f' % (avg_meter.pop('loss_sal')),\n",
    "                  'imps:%.1f' % ((step + 1) * 16 / timer.get_stage_elapsed()),\n",
    "                  'lr: %.4f' % (optimizer.param_groups[0]['lr']),\n",
    "                  'etc:%s' % (timer.str_estimated_complete()), flush=True)\n",
    "\n",
    "    else:\n",
    "        validate(model, val_data_loader)\n",
    "        timer.reset_stage()\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3760155f-13fb-4d8d-ae31-cd05cbbbb945",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/home/maruf/ws2m2/sess/resnet50_cam' + '_saliency_norm.pth')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a574e58e-e7ba-4116-9de4-cd28c7c8a015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
